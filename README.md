# ðŸ“– Planning with Deep Neural Networks: A Survey

ðŸ“„ Long-Horizon Visual Planning with Goal-Conditioned Hierarchical Predictors
https://orybkin.github.io/video-gcp
ðŸ“º https://www.youtube.com/watch?v=bbIQepxyaVw

ðŸ“„ Semi-Parametric Topological Memory for Navigation
https://arxiv.org/abs/1803.00653
ðŸ“º https://www.youtube.com/watch?v=PyQe7nsedkY

ðŸ“„ Hallucinative Topological Memory forZero-Shot Visual Planning
https://arxiv.org/abs/2002.12336.

ðŸ“„ Sparse Graphical Memory for Robust Planning
https://arxiv.org/abs/2003.06417

ðŸ“„ Discovering and Achieving Goals via World Models
https://danijar.com/project/lexa

ðŸ“„ Planning to Explore via Self-Supervised World Models
https://ramanans1.github.io/plan2explore

ðŸ“„ Search on the Replay Buffer: Bridging Planning and Reinforcement Learning
https://arxiv.org/abs/1906.05253

ðŸ“„ Floyd-Warshall Reinforcement Learning: Learning from Past Experiences to Reach New Goals
https://arxiv.org/abs/1809.09318

ðŸ“„ Generalized Hindsight for Reinforcement Learning
https://arxiv.org/abs/2002.11708.

ðŸ“„ Diversity-based Trajectory and Goal Selection with Hindsight Experience Replay
https://arxiv.org/pdf/2108.07887.pdf.

ðŸ“„ Rapid Exploration for Open-World Navigation with Latent Goal Models
https://arxiv.org/abs/2104.05859
https://openreview.net/pdf?id=d_SWJhyKfVw

ðŸ“„ InfoBot: Transfer and Exploration via the Information Bottleneck
https://arxiv.org/abs/1901.10902

ðŸ“„ Learning an embedding space for transferable robot skills
https://openreview.net/forum?id=rk07ZXZRb

ðŸ“„ Parrot: Data-Driven Behavioral Priors for Reinforcement Learning
https://arxiv.org/abs/2011.10024

ðŸ“„ ReLMoGen: Leveraging Motion Generation in Reinforcement Learning for Mobile Manipulation
http://svl.stanford.edu/projects/relmogen

ðŸ“„ HalGan:Addressing Sample Complexity in Visual Tasks Using HER and Hallucinatory GANs
https://arxiv.org/pdf/1901.11529.pdf

ðŸ“„ Long Horizon Visual Planning with Goal-Conditioned Hierarchical Predictors
https://orybkin.github.io/video-gcp/

ðŸ“„ Shortest-Path Constrained Reinforcement Learning for Sparse Reward Tasks
https://arxiv.org/abs/2107.06405.

ðŸ“„ Learning One Representation to Optimize All Rewards 
https://arxiv.org/abs/2103.07945.

ðŸ“„ Model-Based Reinforcement Learning via Latent-Space Collocation
https://orybkin.github.io/latco/

ðŸ“„ Automatic Goal Generation for Reinforcement Learning Agents
https://arxiv.org/abs/1705.06366

ðŸ“„ Skill Preferences: Learning to Extract and Execute Skills from Human Feedback
https://sites.google.com/view/skill-pref.

ðŸ“„ Learning Goal Embeddings via Self-Play for Hierarchical Reinforcement learning-
https://arxiv.org/abs/2111.03189

ðŸ“„ Generating Adjacency-Constrained Subgoals in Hierarchical Reinforcement Learning-
https://arxiv.org/abs/2006.11485 

ðŸ“„ Value Function Spaces: Skill-Centric State Abstractions for Long-Horizon Reasoning- 
https://t.co/yJqJwwCT6r

ðŸ“„ A First-Occupancy Representation for Reinforcement Learning-
https://arxiv.org/abs/2109.13863

ðŸ“„Skill Discovery for Exploration and Planning using Deep Skill Graphs
 https://sites.google.com/brown.edu/dsg/.
 
ðŸ“„Deep Skill Chaining https
 http://sites.google.com/g.hmc.edu/dsc/.
 
ðŸ“„Flexible Option Learning
 https://openreview.net/pdf?id=L5vbEVIePyb.
 
ðŸ“„Finding Options that minimize planning time-
 http://proceedings.mlr.press/v97/jinnai19a/jinnai19a.pdf
 
ðŸ“„Discovering Options for Exploration by Minimizing Cover Time
http://proceedings.mlr.press/v97/jinnai19b/jinnai19b.pdf

ðŸ“„Successor Options 
https://arxiv.org/pdf/1905.05731.pdf


 
 
 
 
 
 
 
 
 
 






















